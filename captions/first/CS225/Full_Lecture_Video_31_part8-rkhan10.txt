Good, very good. So the observation is, that if you have a whole bunch of things in the same bucket, and you go to get your data out. You have to essentially search that whole thing to get your data. So the cost here could be a lot. In the worst to record that observation in the worst case. So insert is always constant time because you always gonna put it in the front, but in the worst case we might have to travel all the way down the list and if it is true that everything mapped to once cell you might to search it all. Any response to that? Any idea about it? Yeah? It's okay? You agree with it? Okay. So that's worst case, but about under SUHA. What does SUHA say is gonna happen here?

How many do you expect if these things are universally distributed over a table, how many do we expect in each chain? Yeah? Close to two in the chain in this example, but in general if I tell you the table sizes N, big N, and your sample size is little n. How many do you expect, and that's a probabilistic an average, on average, how many do you expect in each cell? Right, so good, so this is little n over big N. And insert is a constant time. What do you think about this? What do you think about this? This is foreshadowing. This is important foreshadowing. Are these two the same? They're not?! Raise your hand if you think these two are asymptotically the same. This is discussion not competition. Okay. And uhm raise your hand if you don't think they are the same. Okay. The answer is it depends. Here's what I wanted, here's what I'm gonna use to answer this question, okay? We control the table size. You and me, we're the boss. We are the boss of that hashed, how big that hashed table is. Right? So we can always make it big enough so that this value is whatever we want it to be. Yes? Yeah? So these two in this context are not the same because big N because big N is not a constant. We control it. And we're gonna change it. I think we might be able to, this is foreshadowing, we might be able to imagine when we might change it. Alright any questions about it? Alright so separate chaining you just plug them all in and SUHA saves you is the short story. This is an algorithm that is a very big simplification of a class of hashing strategies, it is sort of the introductory one. It's closed hashing which means all your data will be in the table and here is how it works: if there is not a collision, you just map the key to its position. So sixteen maps to two, eight maps to one, four maps to four, thirteen maps to six, and now life gets interesting. We are gonna hash twenty-nine to one, and it's full. There's already something there. So we increase our additive, our probe number, this is a probe number, and look at the next spot. Oh look, sixth spot two is full two, but when you increase it again to three there's room so we can put twenty-nine right there. Any question about it? So where does eleven go? Into five, good. And how about twenty-two? What's twenty-two's life like?