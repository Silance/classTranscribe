Even if--even if, uhh, the thing I'm looking for is not in the table... This one is for successful, this one is for unsuccessful. Okay. Up there, that same value, we would have to keep our finesse--same number of probes, we'd have to keep our table only half full. Okay, our table only half full, for example. Any question about that? I'm used to having this discussion in the context of that applet--I don't pretend that this is particularly smooth. Alright. Any questions? Is it good? So the idea is that these probe based strategies work fine if you don't let your table get too full. Yeah? Nathan? [question being asked]. No, that was just--four doesn't seem like too many; four is a constant number, and it seems like it'd be pretty quick, right? And I can say to somebody, "oh, we'll never have to go further than four." Okay? It was an arbitrary choice. But it turns out--well, I'll save that punchline for a minute. Alright, any questions about this? Yes? [question being asked]. So, successful is if it's in the table, unsuccessful is if it's not in the table. So if you're looking for a key that is actually there somewhere, versus if you're looking for a key that is not there. That's the only difference, okay? I question... Maybe I shouldn't even break them out. Maybe we should just look at the unsuccessful numbers. Alright, any other questions about this? Any other questions about this? The takeaway is, if your table gets full, look how fast those functions go up. But if your table isn't very full, you're kinda in good shape for these things. Alright, so, uhhh... Let's be a little--let's think about this a little bit. Alright. So, when we were talking about queues, and if I asked you, you know, I've got this queue, what do I do if it fills--what do you say? What's your answer? What if the array fills? I should double the array... and....? Copy the data. Very good. Okay, that's what we used to have. Here's what we have now. I'm gonna change it up a little bit. So, look, we're not going to let the array fill. We're only going to let the array get up to some alpha that we control--some load factor that we control. In practice, the reasonable load factor that is used is approximately 2/3. There's an analytical reason for using this load factor, but in practice, it's about 2/3. So, 'what if the array becomes more than 2/3 full' replaces the question of what happens if the array fills. What if the array is more than 2/3 full? (Alpha greater than 2/3). Now, we don't exactly double the array and copy the data. We... find the first prime greater-than twice the array size. Find first prime greater than twice array size. Because we like prime numbers but we're not gonna--I'll explain that if you want. And then, instead of copying the data, we do something a little bit different... Okay? So, I wanna do this example so that you see what we need to do. So, suppose we have hashed our values into this table, and this hash function h(k) is a hash of some kind, mod table size, which is five. And we've hashed these three values into it. And another piece of data comes along. Now, we're going to find the first prime bigger-than twice the array size--oh look, there it is, and copy the data in, okay? So it's just a straight copy. What's the problem with that? What does our new hash function look like? What does the new hash function look like? It's h 1 of k, mod 11 now. Which means that you will never get these guys back--we changed the hash function. So instead of copying the data, so instead of copying the data, we rehash the data with our new hash function.