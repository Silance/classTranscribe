Um, but it also guarantees that same running time. Okay, so now, let's write the code that does this. Let's write the code that does this. Oh, we're not gonna prove the log n here. We just, we're gonna move right past it. We're gonna be satisfied at this moment of having log n. But we're not gonna take the time to prove it because we're gonna do better. Alright, find has not changed. So the code for find didn't change at all. But the running time of find is gonna change. We didn't even touch it. And its running time is going to change. Alright, so here is UnionBySize. UnionByHeight could be done similarly. I don't even think we ever ask you to do it. I think we always ask you to do UnionBySize. Notice that the new size is the sum of the values at the roots, just like we suspected might be the case. Umm, if, so we got this helper function isBigger that merely, you know, takes the negative of the value in the root, right? And compares them. But I gotta a little bit lost in the equalities there, so I want to test that separately and make sure it did what I thought. So let's see. This is, this means root1's tree has more nodes than root2's. Okay? Alright, so if root1 is bigger, then we're gonna point root2 to root1. And then root1 gets the new size. Okay? Any question about that? Otherwise, we'll do the opposite. Any question about it? Okay, what's the running time of that code? Yeah, it's constant time. Good. Because there's no traversing going on. There is no, there is nothing about the size that any of these structures that affect the running time here, right? We can look up the sizes, are just array look-ups. The comparison is a constant time thing, the condition evaluation. Then we just got a couple of assignments. So this is still a constant time operation. But it has the effect of maintaining the trees as short trees. So now we can say that find is O(log n). Do you remember what was the best we had before we started using these up trees? The naive implementations of, I guess it was probably, umm, using an array? Do you remember what it was for using an array? It was constant time for find, but it was O(n) for taking the union, okay? So this is using an array. And you can go back. Using an array naively I should say. You can go back and review that, okay? So do you like this better? Kinda depends which one you do most often, right? And in fact in a sequence of using this structure, you can only take unions so many times. So this doesn't feel quite satisfying to me yet. Okay? We shouldn't stop here. We should do one more thing. Let's suppose we do a find(4).