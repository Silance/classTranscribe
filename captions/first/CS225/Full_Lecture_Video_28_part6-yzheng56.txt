good? ok. classic balanced but we have already talked a little bit AVL trees are not the only balanced trees.red black trees are another.there are a gazillion slight variations of each.each corresponding to the phd thesis of somebody in the 70'S. Maybe the 60's.Alright so ugh so there are probably variations thereof but these are classic  and any adaptation is probably you know an addition of record key things or some constant time access to part of it things like this.so here are the key contrasts to all of them. Red black trees actually allow for a little strings of red and black parents so the overall height is bounded  by a  a factor 2logn. we proved 2 logn for avl trees but infact if you solve that recurrence more exactly you could get it down to 1.44 max height but in either case they are log heights.The main difference is that red black trees will only have upto 2 rotations upto each operations but avl trees you might need to rotate upon remove all the way up to the tree.avl tree have no rotations along find but i feel red black trees might. Why are we doing this? why are these such great structures?They are kinda cool because we can always give a worse case bound of log n. That is good news.we don't have to worry about the order in which our data comes in.we are gonna build one of these and the rotations  will keep the tree short even for ordered data. umm so that is an improvement over linked lists,arrays and also plain old binary search trees.The other thing the absolute best thing about avl trees is that you can use them to solve other harder problems. The type of problems that they can solve are called range finding that is find 2 values be in the tree in which some query value falls for example or find all the values within a range of numbers that can be done very efficiently and nearest neighbor is a big one so imagine your favorite its your dream moment.Imagine your favorite avl tree, it has got keys in it and it is balanced.And i come to you with keys and i dont really care if the key is in the tree i want the key closest to this one. AVL trees can be used to to do that whereas other faster dictionary structures cant. MP6 is actually a k nearest neighbor search in it in a slightly different structure. Here is the problem.Turns out its possible if you are only looking for a particular key and you know what your keyset is it is possible to search for faster than log n time.That is foreshadowing. And then the other drawback is that we really can only build these avl tree if all our data fits in memory coz we are  poking around in ram for these memory addresses for these keys and our data might be so big that infact doesn't  even fit in memory.These 2 observations define the next two structures that we are gonna look at and we are gonna go bottom to top and later actually after your exam we are gonna address this issue. So that's the setup if the data is so big that it doesn't fit  in main memory where we are gonna put it? Okay so I have got data oh i had this very cool weird experience about i dont know 5 years ago or so so you wouldn't years ago i was sitting in dan roth's office and we were talking about doing  some research on some data that involved calling the web and i was like  oh my gosh the web is so big and he looks at me and like i am crazy because the web is sitting in those 4 hard drives behind you. it was early of bunch of terabytes drives sitting there but it still was sort of cosmic moment where this this i thought was so huge actually fit on  dan roth's desk. it was a little strange for me but nonetheless that entire web no matter what fraction of the web at the time that web wouldnt fit into the ram. so we couldn't build an  avl tree out of all urls for example. We just couldnt do it . Okay so the answer here is no