Good, very good. So the observation is that if you have a whole bunch of things in the same bucket. If you have a whole bunch of things in the same bucket and you go to get your data out, you have to essentially search that whole thing to get your data. OK you have to search your whole thing to get your data. So the cost here could be a lot. In the worst, we're going to record that observation in the worst case. So insert is always constant time cause we're just gonna plunk it in the front, but in the worst case we might have to travel all the way down the list and if it's true that everything maps to one cell you might have to search it all. Any response to that? Any idea about it? Yeah, it OK. Your agree with it? OK. So that's worst case but how about under SUHA. What does SUHA say is gonna happen here? How many do you expect if these things are uniformly distributed over the table si... over the table. How many do you expect in each chain? Yeah. At most two in the chain in this example but in general if I tell you the table size is n, big N and you sample size is little n. How many do you expect, and that's a probabilistic average, on average how many do you expect in each cell? Right, good so this is in this case little n over big n, and the insert is still constant time. What do you think about this? What do you think about this? This is foreshadowing, this is important foreshadowing. Are these two the same? They're not? Raise your hand if you think these two are asymptotically the same. Raise your hand there's you know this is discussion not competition OK. Um and raise you're hand if you don't think they're the same. The answer is it depends. Here's what I wante... Here's what I want to uh... Here's what I'm gonna use to answer this question OK. We control the table size. You and me we're the boss, we're the boss of that hash. How big that hash table is alright? So we can always make it big enough so that this value is whatever we want it to be yes? Yeah. So these two in this context are not the same because big N is not a constant. We control it and we're gonna change it. I think you might be able, this is foreshadowing. We might be able to image when we might change it. Alright any question about this? Any question about it? OK. Alright so separate chaining, you just plunk them all in and SUHA save you is the short story. Alright here is another one. Uh this is an algorithm that uh general is uh very big simplification of a class of uh hashing strategies. It's sort of the introductory one. It's closed hashing which means all your data  will be in the table and here's how it works. Uh, if there's not a collision you just map the key to its position. So sixteen maps to two, eight maps to one, four maps to four, thirteen maps to six. And now life gets interesting, we're gonna hash twenty-nine to one. and it's full there's already something there so we increase our additive, our probe number. This is a probe number, and look at the next spot. Oh look, spot two is full too, but when you increase it again to three there's room and so we can put twenty-nine right there. OK any question about it? So where does eleven go? Into five, good. And how about twenty two? What's  twenty-two's life like?