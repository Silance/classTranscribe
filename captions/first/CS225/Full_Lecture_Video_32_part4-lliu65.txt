He thinks he can get to his data faster if he stores the number of probes it takes. If you could keep track of how many times you have to insert it, then you can save yourself time. You have to maintain it back at the original probe location. The process of that doesn't save you time. Lots of things can hash to the same spot. I can draw you pictures for that later. Double hashing is just adjustment to the step sizes you use for linear probing. So how well do these things do? Here are formulas. Don't memorize. Use analytical skills. Alpha is load factor of the table, equal to number of keys divided by table size. They run in time that depend on this load factor. Here's what they look like. Does your key exist in the table or not? Don't look at them to memorize. Tell me what that function looks like. It's undefined and alpha's limit goes to just more than 0. For less than 1, it's a really huge number. Im going to show you the funcitons in just a minute. As table fills, that expression goes crazy, goes to infinity.