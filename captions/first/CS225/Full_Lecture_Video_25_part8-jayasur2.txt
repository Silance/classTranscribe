greater than.. wait, no, a half of one, probably. Its a lower bound, so you know how Big O is like a less than or equal to? Big O, if you go back and you look at the definition from 173 (prerequisite), you look at the definition, Big O is like less than or equal to. Big Omega is like greater than or equal to and their definitions are symmetric in almost every possible way. Any question about that? Does that satisfy the question? Okay, alright, any other question about this? Okay, so now this says no algorithm, if somebody comes to you and says they have a binary search tree where the key functions work in time < log(n) (they run in constant time) you go "ahh, then its not a binary search tree." You might be doing something else, it might be a dictionary, but if you're using a binary search tree, those functions cannot run in time better than log(n). Okay? This falls in our world of how tall is a binary search tree in general. Its about log(n). Right, that's where that casual conversation goes. Okay, so we did this one, we did that one, lets do the other one as well. Now what we're trying to argue is that h <= some f(n). Okay? No matter what. So what we want to do is go big here and say "okay fine, what's the very largest tree we can make out of n nodeS? Cause the height has to be less than that." What's the tallest tree we can make with n nodes? I don't wanna ask this question, its stupid. Okay, whats the tallest tree we can make with n nodes? n-1 right? n-1. Tallest tree is n-1, so in general, if you have n nodes, the height is always going to be <= n-1. Okay, so you take n nodes, and you look at all possible trees you can, none of them is going to have height greater than n-1. So look, again, we've got a.. close to something that looks like a definition from CS 173 in this "<=". So, instead of "<=" we're gonna right, h is O(n), where we ignore constant factors and we roll the "<=" part into that symbol, into the definition of Big O. Alright? So is this good news or bad news? Bad news right? What if we did this same argument about linked lists? We'd have the same result, so we should all be sitting here thinking "well binary search trees really aren't all that good then? right? Shoot, it was so fun, we had such a good time and its not important to us." Well it turns out the following is true: if you consider the order in which you do the insertion to be random and you look at the heights of the trees of all possible orders that you do, for which you could build the tree, and you take the average of all of those heights, then you get... I'm not gonna tell you what yet, okay? Lets first wrap our minds around the problem okay? So I've got here, seven keys, seven different keys in two different orders. Two different orders. The first one results in a tree that looks like "1, 3, 2, 4, 5, 7, 6" and the second one results in tree that looks like "4, 2, 3, 6, 7, 1, 5" Okay? Now I wanna know how may different arrangements of n keys you might have. I've shown you two here, and they both result in trees of different sizes or heights. But I wanna know how many different ones we would have to draw. This is an easy one, this is not a complexed question. How many different arrangements are there of n keys? Yeah? n factorial is correct. So there are n factorial arrangements.