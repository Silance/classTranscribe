[{"text":"so we run each of this though the new hash function and they may end up in a completely different location in a new array.","width":962},{"text":"but when we go looking for them we know we can find out.","width":258},{"text":"ok, any questions about that?","width":151},{"text":"So, of the right, those are exactly parallel.","width":183},{"text":"we don't fill the array, we don't exactly double the table size, we don't copy the data.","width":395},{"text":"But we have parallel things to do in each of those cases.","width":282},{"text":"Alright any questions about it?","width":97},{"text":"Process called rehashing.","width":218},{"text":"Questions?","width":71},{"text":"twice array size.","width":345},{"text":"so in my worried about having to find the first prime, greater than twice the table size, we can find a prime in a table very quickly.","width":1341},{"text":"You can store a lot of primes to look up, you don't have to compute them.","width":318},{"text":"Certainly enough to create an array of that size.","width":655},{"text":"so the question is where does the two thirds comes from.","width":343},{"text":"Does it strictly apply to linear probing in double hashing?","width":231},{"text":"It's the load factor that corresponds to probe base hashing strategy generally however they are implemented.","width":887},{"text":"In general, you want your table to be two thirds full.","width":453},{"text":"It's gives you sort of feeling or what's going on behind the scene when you use hash map as well.","width":429},{"text":"Alright, any questions about this?","width":167},{"text":"So the question is is there any way of escaping the fact that we are intentionally allocating memory that we are going to use, we admit going in that a third that space is not going to be use.","width":1422},{"text":"I believe the answer to that is no.","width":173},{"text":"You have to allow for data to be mapped in to those cells, otherwise you got a different problem.","width":389},{"text":"I mean that to sort of equivalent to get a full array and then you got an issue.","width":871},{"text":"So we are we?","width":120},{"text":"Without these two collision resolution strategy, one of them just pain out the data.","width":453},{"text":"The other one use probing to place it in the table.","width":381},{"text":"There are others you might be used.","width":348},{"text":"For separate chaining, why not using another hash table?or why not use an avl tree?","width":531},{"text":"Why not use something else instead of just singly linked list?","width":328},{"text":"so the number of variety in that particular structure is astounding.","width":647},{"text":"so these are just sort of basic idea.","width":271},{"text":"Now given these basic ideas which one is better?","width":353},{"text":"The structure speed is weigh faster for probe based hashing, that is, if you can actually fit all your data into an array, that structure will be much faster.","width":1368},{"text":"But if your data is big, then you can't create an array that's very big using your memory effectively.","width":486},{"text":"And so you want to have the ability to hang your data off your structure.","width":344},{"text":"So you have big records, then separate chaining is a better strategy.","width":478},{"text":"And of course this is a huge simplification.","width":191},{"text":"ok, What's structure do hash table replace for use?","width":664},{"text":"What do we use to implement dictionary before?","width":368}]